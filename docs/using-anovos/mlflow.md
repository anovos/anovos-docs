# MLflow Integration

[_MLflow_](https://www.mlflow.org/) is a popular open source solution for managing all aspects of the
machine learning lifecycle.
The platform encompasses four components:

- _MLflow Tracking_ to record code, data, configuration, and results of ML experiments
- _MLflow Projects_ to package data science code in a format that allows it to run reproducibly in different environments
- _MLflow Models_ to deploy ML models in different environments
- _MLflow Model Registry_ to store and manage ML models in a central repository

To learn more about _MLflow_ and its capabilities, see the
[_MLflow_ documentation](https://www.mlflow.org/docs/latest/index.html).

## Reporting _Anovos_ data to _MLflow Tracking_

_Anovos_ integrates with _MLflow_ by reporting workflow metadata and results to _MLflow Tracking_.

To track your workflows with _MLflow_, add an `mlflow` block to your [workflow configuration file](config_file.md):

```yaml
mlflow:
  experiment: "Anovos"                   # The name of the MLflow experiment associated with your workflow
  tracking_uri: "http://127.0.0.1:8889"  # The URL of the MLflow Tracking server
  track_output: True                     # Store the workflow output (i.e., resulting dataset(s))
  track_reports: True                    # Store the generated reports
  track_intermediates: False             # Store any intermediate data generated by your workflow
```

### Current Limitations

It is currently not possible to select which intermediate outputs are stored.
If `track_intermediate` is set to `True`, all intermediate outputs will be stored.

## Using MLflow on Azure Databricks

If you are running _Anovos_ workloads on [Azure Databricks](https://azure.microsoft.com/services/databricks/),
you can use the integrated [Managed MLflow](https://www.databricks.com/product/managed-mlflow) to track
your _Anovos_ runs and artifacts.

To learn more about moving your _Anovos_ workloads to Azure Databricks, see the
[ðŸ“– Setting up _Anovos_ on Azure Databricks](setting-up/on_azure_databricks.md) guide.

To track an _Anovos_ workflow with Managed MLflow, you first need to create a new MLflow experiment.
This is possible either through the Databricks Machine Learning UI or the MLflow API.
Please refer to [the Azure Databricks documentation](https://docs.databricks.com/mlflow/tracking.html#experiments)
for detailed and up-to-date instructions.

Once you have created an experiment for your workflow, you can then use its "Location" as the `experiment_name`
in the _Anovos_ workflow configuration's `mlflow` config block.
The `tracking_uri` needs to be set to `databricks`.

ðŸ¤“ _Example:_

```yaml
mlflow:
  experiment: "/Users/your_user_name@your_domain.tld/your_experiment_name"
  tracking_uri: "databricks"
  track_output: True                     # Store the workflow output (i.e., resulting dataset(s))
  track_reports: True                    # Store the generated reports
  track_intermediates: False             # Store any intermediate data generated by your workflow
```

## Roadmap

We're exploring integration of _Anovos_ with _MLflow Projects_ and _MLFlow Pipelines_.
[Let us know](../community/communication.md) which capabilities you'd like to see in future versions of _Anovos_!
