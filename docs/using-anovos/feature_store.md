# Feature Store Integration

Feature stores are an essential building block of a modern MLOps setup.
For an introduction into the concept and an overview of available options and vendors, see the
[Feature Store Comparison & Evaluation](https://mlops.community/learn/feature-store/)
on the [MLOps Community website](https://mlops.community/).

_Anovos_ provides integration with [Feast](https://www.feast.dev), a widely used open source feature store,
out of the box.
Using the same abstractions, it is straightforward to integrate _Anovos_ with other feature stores.

If there is a particular feature store integration you'd like to see supported by _Anovos_,
[let us know!](../community/communication.md)

## Using _Anovos_ with Feast

The following guide describes how to use _Anovos_ to push data to Feast.
We assume that you are familiar with the fundamentals of both _Anovos_ workflows and Feast.

For an introduction to Feast, see [ðŸ“– the Feast Quickstart guide](https://docs.feast.dev/getting-started/quickstart).

### Prerequisites

In order to use _Anovos_ with Feast, you need to install it:

```bash
pip install feast
```

Next, we'll instantiate a new Feast repository:

```bash
feast init anovos_repo
```

ðŸ¤“  _Note: You can also use an existing repository._
In this case, Anovos will simply add a new file anovos.py containing the feature definitions as well as the output file to the existing repository.

### Adding the Feast export to your _Anovos_ workflow

To export data to Feat at the end of a workflow run, you need to add the `write_feast_features` block
to the configuration file. (To learn more about the configuration file in general and available options,
see [ðŸ“– the configuration file documentation](config_file.md).)

You can use the following template as a starting point:

```yaml
write_feast_features:
  file_path: "../anovos_repo/"                     # the location of your Feast repository
  entity:
    name: "income"                                 # the Feast entity
    description: "this entity is a ...."           # the entity description used by Feast
    id_col: 'ifa'                                  # the primary key columnm to identify this entity by
  file_source:
    description: 'data source description'         # the data source description used by Feast
    owner: "me@business.com"                       # the data source owner registered in Feast
    timestamp_col: 'event_time'                    # ...
    create_timestamp_col: 'create_time_col'        # ...
  feature_view:
    name: 'income_view'                            # the name of the generated feature view
    owner: 'view@owner.com'                        # the view owner registered in Feast
    ttl_in_seconds: 36000000                       # the time to live in seconds for features in this view. Feast will use this value to look backwards when performing point in time joins
  service_name: 'income_feature_service'           # the name of the feature service generated by the workflow
  file_configs:
    mode: overwrite                                # ...
```

Let's break this down!

The following yaml block generates an [entity definition in Feast](https://docs.feast.dev/v/master/getting-started/concepts/entity). This block and all its child elements are mandatory.
the ```name``` elements specifies the entity name. The ```description``` element provides a human readable description to be displayed in the Feast UI. Element ```id_col``` specifies the primary key colunm of the entity.
```yaml
entity:
    name: "income"
    description: "this entity is a ...."
    id_col: 'ifa'
```

The following yaml block generates an [file source definition in Feast](https://docs.feast.dev/getting-started/concepts/data-source). This block and all its children are mandatory.
The ```owner``` elemetn describes the owner of the file datas source in form of a email address. The two elements ```timestamp_col``` and ```create_timestamp_col``` refer to timestamped columns [used when retreiving data](https://docs.feast.dev/getting-started/concepts/point-in-time-joins).
```yaml
file_source:
    description: 'data source description'
    owner: "me@business.com"
    timestamp_col: 'event_time'
    create_timestamp_col: 'create_time_col'
```

The following yaml block generates an [feature view definition in Feast](https://docs.feast.dev/getting-started/concepts/feature-view). This block and all its children are mandatory.
```yaml
feature_view:
    name: 'income_view'
    owner: 'view@owner.com'
    ttl_in_seconds: 3600
```

The following elements generates an [feature service definition in Feast](https://docs.feast.dev/getting-started/concepts/feature-retrieval). This element is optional.
```yaml
service_name: 'income_feature_service'
```
The block `file_configs` (optional): Rest of the valid configuration can be passed through this options e.g.,
  repartition,  mode,  compression,  header,  delimiter,  inferSchema etc. This might look like:
```yaml
file_configs:
  mode: overwrite
```

### Exporting data to Feast

Run your anovos workflow with the configuration above

### Apply new features and materialize the feature data in the offline store

Once the workflow has finished, switch into the folder of `anovos_feature` repository and
apply the changed feature definitions and materialize the features:

```bash
cd anovos_repo
feast apply
feast materialize `date "+%Y-%m-%dT"` `date "+%Y-%m-%dT%H:%M:%S"`
```

### Verify feature definitions in Feast UI

To verify that the features have been loaded correctly, you can check them using Feast's UI.
Run

```bash
feast ui
```

and access the Feast UI at [`http://127.0.0.1:8888`](http://127.0.0.1:8888). The UI gives a realtime overview about data sources, entities, feature views etc. of the entire feature repository (across multiples .py files).

There, ...

### Retrieve feature data from Feast

The following script shows how to access historical data e.g. for the purpose of training an ML model. For more information, please access the [feast documentation on feature retreival](https://docs.feast.dev/getting-started/concepts/feature-retrieval). Documentation on how to specify ```event_time``` and its use in point in time joins can be found [here](https://docs.feast.dev/getting-started/concepts/point-in-time-joins).

```python
from feast import FeatureStore
import pandas as pd

store = FeatureStore(repo_path="./anovos_repo")

# ACCESS HISTORICAL FEATURES

# Either read directly from parquet file generated by the Anovos workflow or generate manually
income_entities = pd.DataFrame.from_dict(
    {
        "ifa": [
            "27a",
            "30a",
            "475a",
            "965a",
            "1678a",
            "1698a",
            "1807a",
            "1951a",
            "2041a",
            "2215a",
        ],
        "event_time": [
            datetime.now(),
            datetime.now(),
            datetime.now(),
            datetime.now(),
            datetime.now(),
            datetime.now(),
            datetime.now(),
            datetime.now(),
            datetime.now(),
            datetime.now(),
        ],
    }
)

fs = feast.FeatureStore(repo_path=repo_path)

# alternative 1: retrieve features via explicit specification
income_features_df = fs.get_historical_features(
    entity_df=income_entities,
    features=[
        "income_view:income",
        "income_view:latent_0",
        "income_view:latent_1",
        "income_view:latent_2",
        "income_view:latent_3",
    ],
).to_df()
print(income_features_df.head())

# alternative 2: retreive features using the feature serice
feature_service = fs.get_feature_service("income_feature_service")
income_features_by_service_df = fs.get_historical_features(
    features=feature_service, entity_df=income_entities
).to_df()
print(income_features_by_service_df.head())

# Train your model

...
```

## Integrating _Anovos_ with other feature stores
