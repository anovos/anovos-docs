# Feature Store Integration

Feature stores are an essential building block of a modern MLOps setup.
For an introduction into the concept and an overview of available options and vendors, see the
[Feature Store Comparison & Evaluation](https://mlops.community/learn/feature-store/)
on the [MLOps Community website](https://mlops.community/).

_Anovos_ provides integration with [Feast](https://www.feast.dev), a widely used open source feature store,
out of the box.
Using the same abstractions, it is straightforward to integrate _Anovos_ with other feature stores.

If there is a particular feature store integration you'd like to see supported by _Anovos_,
[let us know!](../community/communication.md)

## Using _Anovos_ with Feast

### Prerequisites

```bash
feast init anovos_repo
```

### Adding Feast export to your _Anovos_ workflow

Copy the following template into your workflow configuration file:

```yaml
write_feast_features:
  file_path: "../anovos_repo/"
  entity:
    name: "income"
    description: "this entity is a ...."
    id_col: 'ifa'
  file_source:
    description: 'data source description'
    owner: "me@business.com"
    timestamp_col: 'event_time'
    create_timestamp_col: 'create_time_col'
  feature_view:
    name: 'income_view'
    owner: 'view@owner.com'
    ttl_in_seconds: 3600
    create_timestamps: True
  feature_service:
    name: 'income_feature_service'
  file_configs:
    mode: overwrite
```

### Exporting data to Feast
Run your anovos workflow with the configuration above

### Apply new features and materialize the feature data in the offline store
Change into the anovos feature repository, apply the vhanged feature definitions and materilaize the data

```bash
cd anovos_repo
feast apply
feast materialize `date "+%Y-%m-%dT"` `date "+%Y-%m-%dT%H:%M:%S"`
```

### Verify feature definitions in Feast UI

```bash
feast ui
```

You can now access the local feast ui under "https://127.0.0.1:8888"

### use features offline for training

```python
  store = FeatureStore(repo_path="./anovos_repo")

  print("--- Historical features ---")

  # Eiterh read directly from parquet file generated by anovos workflow or generate manually 
  entity_df = pd.DataFrame.from_dict(
      {
          "ifa": ['', '', '' ''], # add some ids
          "event_timestamp": [
              datetime(2022, 5, 31, 14, 59, 42), # add datetiem entries corresponding to timestamps of the generated features
              datetime(2022, 5, 31, 8, 12, 10),
              datetime(2022, 5, 31, 16, 40, 26),
              datetime(2022, 5, 31, 15, 1, 12),
          ],
      }
  )
  training_df = store.get_historical_features(
      entity_df=entity_df,
      features=[
          "income_view:age",
          "income_view:workclass",
          "income_view:education",
          "income_view:occupation",
          # add more columns here
      ],
  ).to_df()
  print(training_df.head())

  # train your model ...

```




## Integrating _Anovos_ with other feature stores
